{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHkgaZ1g3mUODXTDJTR1tm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aman7Rathore/SEO-analyzer/blob/main/Seo_Keyword_Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hbcFg8p84em",
        "outputId": "41a09e1a-91eb-4bcd-c084-8e7f8aacdd6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a function for seo analysis like title,metatags and meta descriptions\n",
        "def seo_analysis(url):\n",
        "  #Send a request to get the url from internet\n",
        "  res = requests.get(url).text\n",
        "  #Parse the html content using BeautifulSoup\n",
        "  soup = BeautifulSoup(res,\"html.parser\")\n",
        "\n",
        "  #Create lists to store values\n",
        "  good = []\n",
        "  bad = []\n",
        "  keywords = []\n",
        "\n",
        "  #(1)grab the title\n",
        "\n",
        "  title = soup.find('title').text\n",
        "  if title:\n",
        "    good.append(f\"Title Exists : {title}\")\n",
        "  else :\n",
        "    bad.append(f\"Title doesn't Exists\")\n",
        "  #(2)grab the metadescription\n",
        "\n",
        "  meta = soup.find('meta',attrs={'name':'description'})['content']\n",
        "  if meta:\n",
        "    good.append(f\"meta_description exists:{meta}\")\n",
        "  else :\n",
        "    bad.append(f\"meta not exists\")\n",
        "\n",
        "  #(3)grab the heading\n",
        "\n",
        "  hs = ['h1','h2','h3']\n",
        "  h_tags = []\n",
        "  for h in soup.find_all(hs):\n",
        "    good.append(f\"{h.name}\")\n",
        "    h_tags.append(h.name)\n",
        "\n",
        "  if \"h1\" not in h_tags:\n",
        "    bad.append(\"No h1 found\")\n",
        "\n",
        "  #(4)grab the headings without alt\n",
        "  for i in soup.find_all('img',alt=''):\n",
        "    bad.append(f\"No ALT found:{i}\")\n",
        "  res = requests.get(url).text\n",
        "  soup = BeautifulSoup(res,'html.parser')\n",
        "\n",
        "\n",
        "  body = soup.find('body').text\n",
        "\n",
        "# Grab the text from the body of html\n",
        "  body = soup.find('body').text\n",
        "\n",
        "# Extract all the words in the body and lowercase them in a list\n",
        "  words = [i.lower() for i in word_tokenize(body)]\n",
        "\n",
        "# Grab a list of English stopwords\n",
        "  sw = nltk.corpus.stopwords.words('english')\n",
        "  new_words = []\n",
        "\n",
        "# Put the tokens which are not stopwords and are actual words (no punctuation) in a new list\n",
        "  for i in words:\n",
        "    if i not in sw and i.isalpha():\n",
        "      new_words.append(i)\n",
        "\n",
        "\n",
        "  freq = nltk.FreqDist(new_words)\n",
        "  keywords= freq.most_common(10)\n",
        "\n",
        "# Print the results\n",
        "  print(\"Keywords: \", keywords)\n",
        "  print(\"The Good: \", good)\n",
        "  print(\"The Bad: \", bad)\n",
        ""
      ],
      "metadata": {
        "id": "-bj_NBDw9eOW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seo_analysis(\"https://www.searchenginejournal.com/machine-learning-practical-introduction-seo-professionals/366304/#close\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQK2nyjGLpxf",
        "outputId": "d472050d-636c-4d87-ed8e-1edf35662de3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keywords:  [('seo', 36), ('learning', 22), ('google', 21), ('search', 21), ('data', 20), ('machine', 19), ('training', 19), ('code', 17), ('need', 15), ('page', 15)]\n",
            "The Good:  ['Title Exists : A Practical Introduction to Machine Learning for SEO Professionals', 'meta_description exists:This guide to machine learning will teach you how to build a model to predict whether adding keywords in title tags can increase organic search clicks.', 'h3', 'h3', 'h3', 'h3', 'h3', 'h3', 'h1', 'h2', 'h2', 'h2', 'h3', 'h3', 'h2', 'h2', 'h3', 'h2', 'h2']\n",
            "The Bad:  []\n"
          ]
        }
      ]
    }
  ]
}